{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Rental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDPの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, sys, random\n",
    "from general import MDP\n",
    "\n",
    "class CRStation:\n",
    "    def __init__(self, cap, expRent, expRet):\n",
    "        self.cap = cap; self.expRent = expRent; self.expRet = expRet\n",
    "\n",
    "class MDP_CarRental(MDP):\n",
    "\n",
    "    def nbr_act(self, a):\n",
    "        if a == self.maxTrans:    return [a-1, a]\n",
    "        elif a == -self.maxTrans: return [a, a+1]\n",
    "        else:                     return [a-1, a, a+1]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.maxTrans = 5\n",
    "        self.rewRent = 10\n",
    "        self.costTrans = 2\n",
    "        self.stn = [CRStation(20, 3, 3), CRStation(20, 4, 2)]\n",
    "        # self.stn = [CRStation(20, 8, 8), CRStation(20, 12, 9)]\n",
    "        # self.stn = [CRStation(5, 3, 3), CRStation(5, 4, 2)]\n",
    "\n",
    "        states = [(x,y) for x in range(self.stn[0].cap + 1)\n",
    "                        for y in range(self.stn[1].cap + 1)]\n",
    "        actions = list(range(-self.maxTrans, self.maxTrans + 1))\n",
    "        actNbr = { a: self.nbr_act(a) for a in actions }\n",
    "        super().__init__(states, actions, 0.9, actNbr=actNbr)\n",
    "\n",
    "        self.poisson = {}\n",
    "        self.poissonA = {}\n",
    "        for i in [0,1]:\n",
    "            for lam in [self.stn[i].expRent, self.stn[i].expRet]:\n",
    "                self.calcPoisson(lam, self.stn[i].cap)\n",
    "        self.prep_dyn()\n",
    "\n",
    "    def calcPoisson(self, lam, maxN):\n",
    "        if lam in self.poisson and len(self.poisson[lam]) >= maxN + 1:\n",
    "            return\n",
    "        e = math.exp(-lam)\n",
    "        last = e\n",
    "        lastA = 1.0\n",
    "        self.poisson[lam] = [last]\n",
    "        self.poissonA[lam] = [lastA]\n",
    "        for n in range(1, maxN+1):\n",
    "            lastA -= last\n",
    "            last *= lam / n\n",
    "            self.poisson[lam].append(last)\n",
    "            self.poissonA[lam].append(lastA)\n",
    "\n",
    "    # The probability and combined reward for transfering from\n",
    "    # m to k; i.e. car number was m in the beginning of the day\n",
    "    # and k at the end of the day.  There should exist number w\n",
    "    # such that w cars were rent and k-(m-w) were returned.\n",
    "    # Note that in the cases of w == m and k == cap, probability\n",
    "    # should be accumulated.\n",
    "    def rentRet(self, i, m, k):\n",
    "        pSum = 0.0\n",
    "        rSum = 0.0\n",
    "        pWArr = self.poissonA if k == self.stn[i].cap else self.poisson\n",
    "        for w in range(m+1):\n",
    "            if m - w > k: continue\n",
    "            pVArr = self.poissonA if w == m else self.poisson\n",
    "            pV = pVArr[self.stn[i].expRent][w]\n",
    "            pW = pWArr[self.stn[i].expRet][k - (m-w)]\n",
    "            p = pV * pW\n",
    "            pSum += p\n",
    "            r = self.rewRent * w\n",
    "            rSum += p * r\n",
    "        return (pSum, rSum / pSum)\n",
    "\n",
    "    def prep_dyn(self):\n",
    "        self.tblRR = [[[self.rentRet(i, m, k)\n",
    "                        for k in range(self.stn[i].cap + 1)]\n",
    "                       for m in range(self.stn[i].cap + 1)]\n",
    "                      for i in [0,1]]\n",
    "\n",
    "    def dyn(self, s, a):\n",
    "        rv = []\n",
    "        (n0, n1) = s\n",
    "        (m0, m1) = (n0 + a, n1 - a)\n",
    "        if m0 < 0 or m1 < 0 \\\n",
    "           or m0 > self.stn[0].cap or m1 > self.stn[1].cap:\n",
    "            return []\n",
    "        rewT = -self.costTrans * abs(a)\n",
    "        for k0 in range(self.stn[0].cap + 1):\n",
    "            for k1 in range(self.stn[1].cap + 1):\n",
    "                (p0, r0) = self.tblRR[0][m0][k0]\n",
    "                (p1, r1) = self.tblRR[1][m1][k1]\n",
    "                rv.append((p0 * p1, (k0, k1), rewT + r0 + r1))\n",
    "        return rv\n",
    "    \n",
    "    def simulate(self, pol, init0, init1, duration):\n",
    "        def rand(lam, maxN):\n",
    "            for j in range(1, maxN+1):\n",
    "                x = random.random()\n",
    "                if self.poissonA[lam][j] < x: return (j-1)\n",
    "            return maxN\n",
    "\n",
    "        m0, m1 = init0, init1\n",
    "        revenue = 0\n",
    "        for i in range(duration):\n",
    "            reqRent0 = rand(self.stn[0].expRent, self.stn[0].cap)\n",
    "            reqRent1 = rand(self.stn[1].expRent, self.stn[1].cap)\n",
    "            reqRet0 = rand(self.stn[0].expRet, self.stn[0].cap)\n",
    "            reqRet1 = rand(self.stn[0].expRet, self.stn[1].cap)\n",
    "            rent0 = min(reqRent0, m0)\n",
    "            rent1 = min(reqRent1, m1)\n",
    "            m0 = min(m0 - rent0 + reqRet0, self.stn[0].cap)\n",
    "            m1 = min(m1 - rent1 + reqRet1, self.stn[1].cap)\n",
    "            a = pol[(m0, m1)][0][1]\n",
    "            m0 += a\n",
    "            m1 -= a\n",
    "            revenue += self.rewRent * (rent0 + rent1) - a * self.costTrans\n",
    "        return revenue\n",
    "\n",
    "    def write_policy(self, pol, fp):\n",
    "        for n0 in range(self.stn[0].cap + 1):\n",
    "            for n1 in range(self.stn[1].cap + 1):\n",
    "                print(f'{pol[(n0,n1)][0][1] : 2}', end='', file=fp)\n",
    "            print(file=fp)\n",
    "        print(file=fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "だいたいは指定されているように書けば良い．\n",
    "ただし，dyn メソッドを愚直に書くと，2箇所のステーションで貸す台数と返される台数があるから，\n",
    "駐車場サイズの4重ループを回すことになって，時間がかかりすぎる (Pythonだからね...)．\n",
    "内側のループ (返される方の処理) の結果を事前に計算してリストに保存する (prep_dynメソッド) ことで高速化している．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### インスタンスの生成\n",
    "\n",
    "* carRental : インスタンス\n",
    "* pol0 : 常に車を移動しないポリシー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carRental = MDP_CarRental()\n",
    "pol0 = { s : [(1.0, 0)] for s in carRental.states }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ポリシー反復"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doPolicyIter():\n",
    "    (pol, v, ir) = carRental.policy_iter(pol=pol0, thr=0.01, intRes=2)    \n",
    "    log = 'logCRa.txt'\n",
    "    with open(log, 'w') as fp:\n",
    "        for (pol, v, ir2) in ir:\n",
    "            print('iter for eval: ', len(ir2), file=fp)\n",
    "            carRental.write_policy(pol, fp)\n",
    "        print(f'Printed to {log}')\n",
    "    return pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pol_opt = doPolicyIter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義通りのポリシー反復．テキストの設定だと threshold = 0.01 で，30秒弱かかる．\n",
    "\n",
    "ログ出力には，各ポリシーについて，評価が収束するまでの回数を表示している．\n",
    "最初のうちは収束するのに回数を要しているが，終盤では回数が少ないことがわかる．\n",
    "あるポリシーに関する価値関数が，他の (と言っても，それに近い) ポリシーの初期値として優れていることがわかる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ポリシーの比較\n",
    "\n",
    "最適ポリシーが得られたわけだが，最初のゼロ・ポリシーに比べてどれくらい違うのか，シミュレーションをしてみる．\n",
    "各々のポリシーで1セット duration 日間の営業を iteration セット実施して，得られる利益を比較する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doSimulation():\n",
    "    def disp(label, rev):\n",
    "        print(f'{label : <16}total rev = {sum(rev) : 8d}, list of results: {rev}')\n",
    "        \n",
    "    duration = 300\n",
    "    init0, init1 = 10, 10\n",
    "    iteration = 100\n",
    "    rev0 = [carRental.simulate(pol0, init0, init1, duration)\n",
    "            for _ in range(iteration)]\n",
    "    revOpt = [carRental.simulate(pol_opt, init0, init1, duration)\n",
    "              for _ in range(iteration)]\n",
    "    disp('zero policy', rev0)\n",
    "    disp('optimal policy', revOpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doSimulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 価値反復"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doValueIter():\n",
    "    pol, v, ir = carRental.value_iter(thr=0.01, intRes=1)\n",
    "    print([int(d*100)/100 for d in ir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time doValueIter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義通りの価値反復．テキストの設定だと threshold = 0.01 で，80秒強かかる．\n",
    "表示しているのは，各反復における，前回の価値関数の値の差の絶対値の最大値である．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能に関する実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doValueIterMix():\n",
    "    pol, v, ir = carRental.value_iter_mix(thr=0.01, rep=10, intRes=1)\n",
    "    print([int(d*100)/100 for d in ir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time doValueIterMix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義通りの価値反復は，ポリシーの改善とポリシー評価を1回交替に行う．(このMDPでは) ポリシー改善のためには多数のアクションを比較しなければならず，非効率であると思われる．そこで，ポリシー評価を30回行う毎にポリシー改善を行うようにしてみた．\n",
    "\n",
    "実行時間が14秒弱に縮まった．(参考: 1:10=22.3sec, 1:20=15.2sec, 1:30=13.6sec, 1:40=14.7sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doValueIterNbrOnly():\n",
    "    pol, v, ir = carRental.value_iter(thr=0.01, intRes=1, nbrOnly=True)\n",
    "    print([int(d*100)/100 for d in ir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time doValueIterNbrOnly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ポリシー改善の際に全アクションを比較するのでなく，現在採用されているアクションと1つだけ違う値のアクションのみを比較するようにしてみた．実行時間が30秒強に縮まった．\n",
    "\n",
    "* 上記と組み合わせてみると良いかもしれない (試していない) が，ポリシー改善の頻度を下げているので，効果は限定的であるような気がする．\n",
    "* 一般のMDPでは，あるアクションと別のアクションが「隣り」だの「近い」だのが定義できないといけない．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
